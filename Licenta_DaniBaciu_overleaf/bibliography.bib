@inproceedings{mainpaper,
    title = "Comparing Feature-Engineering and Feature-Learning Approaches for Multilingual Translationese Classification",
    author = "Pylypenko, Daria  and
      Amponsah-Kaakyire, Kwabena  and
      Dutta Chowdhury, Koel  and
      van Genabith, Josef  and
      Espa{\~n}a-Bonet, Cristina",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.676",
    doi = "10.18653/v1/2021.emnlp-main.676",
    % pages = "8596--8611",
}

@article{2_translationese,
author = { Sara   Laviosa },
title = {Corpus-based translation studies: Where does it come from? Where is it going?},
journal = {Language Matters},
volume = {35},
number = {1},
pages = {6-27},
year  = {2004},
publisher = {Routledge},
doi = {10.1080/10228190408566201},
URL = { 
        https://doi.org/10.1080/10228190408566201
},
}


@article{2_4_translationese,
author = {Volansky, Vered and Ordan, Noam and Wintner, Shuly},
year = {2014},
month = {01},
pages = {},
title = {On the features of translationese},
volume = {30},
journal = {Digital Scholarship in the Humanities},
doi = {10.1093/llc/fqt031}
}

@article{background,
year = {2021},
month = {07},
pages = {},
title = {Progress in Machine Translation},
volume = {18},
journal = {Engineering},
doi = {10.1016/j.eng.2021.03.023}
}

@misc{attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{BERT,
author = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina N. Toutanova},
year = {2018},
month = {6},
pages = {},
title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
url  = {https://arxiv.org/abs/1810.04805},
}

@article{BERT-2,
author = {Thomas Vakili and Anastasios Lamproudis and Aron Henriksson and Hercules Dalianis},
year = {2022},
month = {6},
pages = {},
title = {Downstream Task Performance of BERT Models Pre-Trained Using
Automatically De-Identified Clinical Data},
url  = {http://www.lrec-conf.org/proceedings/lrec2022/pdf/2022.lrec-1.451.pdf},
}

@article{huggingfaces,
      title={HuggingFace's Transformers: State-of-the-art Natural Language Processing}, 
      author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
      year={2020},
      eprint={1910.03771},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{activation,
title	= {Searching for Activation Functions},
author	= {Prajit Ramachandran and Barret Zoph and Quoc Le},
year	= {2018},
URL	= {https://arxiv.org/pdf/1710.05941.pdf}
}

@article{cnn,
      title={An Introduction to Convolutional Neural Networks}, 
      author={Keiron O'Shea and Ryan Nash},
      year={2015},
      eprint={1511.08458},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}

@article{layers,
  author={Nguyen, Huu-Thiet and Li, Sitan and Cheah, Chien Chern},
  journal={IEEE Access}, 
  title={A Layer-Wise Theoretical Framework for Deep Learning of Convolutional Neural Networks}, 
  year={2022},
  volume={10},
  number={},
  pages={14270-14287},
  doi={10.1109/ACCESS.2022.3147869}}

@inproceedings{amponsah-kaakyire-etal-2022-explaining,
    title = "Explaining Translationese: why are Neural Classifiers Better and what do they Learn?",
    author = "Amponsah-Kaakyire, Kwabena  and
      Pylypenko, Daria  and
      Genabith, Josef  and
      Espa{\~n}a-Bonet, Cristina",
    booktitle = "Proceedings of the Fifth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.blackboxnlp-1.23",
    pages = "281--296",
    abstract = "Recent work has shown that neural feature- and representation-learning, e.g. BERT, achieves superior performance over traditional manual feature engineering based approaches, with e.g. SVMs, in translationese classification tasks. Previous research did not show $(i)$ whether the difference is because of the features, the classifiers or both, and $(ii)$ what the neural classifiers actually learn. To address $(i)$, we carefully design experiments that swap features between BERT- and SVM-based classifiers. We show that an SVM fed with BERT representations performs at the level of the best BERT classifiers, while BERT learning and using handcrafted features performs at the level of an SVM using handcrafted features. This shows that the performance differences are due to the features. To address $(ii)$ we use integrated gradients and find that $(a)$ there is indication that information captured by hand-crafted features is only a subset of what BERT learns, and $(b)$ part of BERT{'}s top performance results are due to BERT learning topic differences and spurious correlations with translationese.",
}

@article{rabinovich-wintner-2015-unsupervised,
    title = "Unsupervised Identification of Translationese",
    author = "Rabinovich, Ella  and
      Wintner, Shuly",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "3",
    year = "2015",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/Q15-1030",
    doi = "10.1162/tacl_a_00148",
    pages = "419--432",
    abstract = "Translated texts are distinctively different from original ones, to the extent that supervised text classification methods can distinguish between them with high accuracy. These differences were proven useful for statistical machine translation. However, it has been suggested that the accuracy of translation detection deteriorates when the classifier is evaluated outside the domain it was trained on. We show that this is indeed the case, in a variety of evaluation scenarios. We then show that unsupervised classification is highly accurate on this task. We suggest a method for determining the correct labels of the clustering outcomes, and then use the labels for voting, improving the accuracy even further. Moreover, we suggest a simple method for clustering in the challenging case of mixed-domain datasets, in spite of the dominance of domain-related features over translation-related ones. The result is an effective, fully-unsupervised method for distinguishing between original and translated texts that can be applied to new domains with reasonable accuracy.",
}

@inproceedings{xjsdhchuc3oiqwe,
author = {Ilisei, Iustina and Inkpen, Diana and Corpas Pastor, Gloria and Mitkov, Ruslan},
year = {2010},
month = {03},
pages = {503-511},
title = {Identification of Translationese: A Machine Learning Approach},
volume = {6008},
isbn = {978-3-642-12115-9},
doi = {10.1007/978-3-642-12116-6_43}
}

@misc{rabinovich2016parallel,
      title={A Parallel Corpus of Translationese}, 
      author={Ella Rabinovich and Shuly Wintner and Ofek Luis Lewinsohn},
      year={2016},
      eprint={1509.03611},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{rubino-etal-2016-information,
    title = "Information Density and Quality Estimation Features as Translationese Indicators for Human Translation Classification",
    author = "Rubino, Raphael  and
      Lapshinova-Koltunski, Ekaterina  and
      van Genabith, Josef",
    booktitle = "Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N16-1110",
    doi = "10.18653/v1/N16-1110",
    pages = "960--970",
}

@article{3wdesdfjknm3,
author = {Popel, Martin and Tomková, Markéta and Tomek, Jakub and Kaiser, Łukasz and Uszkoreit, Jakob and Bojar, Ondřej and Zabokrtsky, Zdenek},
year = {2020},
month = {09},
pages = {4381},
title = {Transforming machine translation: a deep learning system reaches news translation quality comparable to human professionals},
volume = {11},
journal = {Nature Communications},
doi = {10.1038/s41467-020-18073-9}
}

@article{iyuntbrvercs,
author = {Ustaszewski, Michael},
year = {2021},
month = {03},
pages = {1-19},
title = {Towards a machine learning approach to the analysis of indirect translation},
volume = {14},
journal = {Translation Studies},
doi = {10.1080/14781700.2021.1894226}
}

@article{ew4rvetbrfeda,
author = {Vasheghani Farahani, Mehrdad},
year = {2020},
month = {09},
pages = {},
title = {Adequacy in Machine vs. Human Translation: A Comparative Study of English and Persian Languages},
volume = {4},
journal = {Applied Linguistics Research Journal},
doi = {10.14744/alrj.2020.98700}
}

@article{efscrvdtbfybg5srf4aed,
author = {Zhang, Qiang},
year = {2022},
month = {10},
pages = {},
title = {Cross-Context Accurate English Translation Method Based on the Machine Learning Model},
volume = {2022},
journal = {Mathematical Problems in Engineering},
doi = {10.1155/2022/9396650}
}

@inproceedings{bizzoni-etal-2020-human,
    title = "How Human is Machine Translationese? Comparing Human and Machine Translations of Text and Speech",
    author = "Bizzoni, Yuri  and
      Juzek, Tom S  and
      Espa{\~n}a-Bonet, Cristina  and
      Dutta Chowdhury, Koel  and
      van Genabith, Josef  and
      Teich, Elke",
    booktitle = "Proceedings of the 17th International Conference on Spoken Language Translation",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.iwslt-1.34",
    doi = "10.18653/v1/2020.iwslt-1.34",
    pages = "280--290",
    abstract = "Translationese is a phenomenon present in human translations, simultaneous interpreting, and even machine translations. Some translationese features tend to appear in simultaneous interpreting with higher frequency than in human text translation, but the reasons for this are unclear. This study analyzes translationese patterns in translation, interpreting, and machine translation outputs in order to explore possible reasons. In our analysis we {--} (i) detail two non-invasive ways of detecting translationese and (ii) compare translationese across human and machine translations from text and speech. We find that machine translation shows traces of translationese, but does not reproduce the patterns found in human translation, offering support to the hypothesis that such patterns are due to the model (human vs machine) rather than to the data (written vs spoken).",
}

@misc{fan2023bibliometric,
      title={A Bibliometric Review of Large Language Models Research from 2017 to 2023}, 
      author={Lizhou Fan and Lingyao Li and Zihui Ma and Sanggyu Lee and Huizi Yu and Libby Hemphill},
      year={2023},
      eprint={2304.02020},
      archivePrefix={arXiv},
      primaryClass={cs.DL}
}
@misc{he2023exploring,
      title={Exploring Human-Like Translation Strategy with Large Language Models}, 
      author={Zhiwei He and Tian Liang and Wenxiang Jiao and Zhuosheng Zhang and Yujiu Yang and Rui Wang and Zhaopeng Tu and Shuming Shi and Xing Wang},
      year={2023},
      eprint={2305.04118},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{ledakcurbsvwaceiu4b,
author = {Wintner, Shuly},
year = {2017},
month = {07},
pages = {38-58},
title = {Computational Approaches to Translation Studies},
isbn = {978-3-319-61163-1},
doi = {10.1007/978-3-319-61164-8_2}
}
@inproceedings{q3kdbwc4uaebxui,
author = {Moschitti, Alessandro and Basili, Roberto},
year = {2004},
month = {04},
pages = {181-196},
title = {Complex Linguistic Features for Text Classification: A Comprehensive Study},
volume = {2997},
isbn = {978-3-540-21382-6},
journal = {Proceedings of the 26th European Conference on Information Retrieval (ECIR)},
doi = {10.1007/978-3-540-24752-4_14}
}


@article{DBLP:journals/corr/abs-1810-04805,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {CoRR},
  volume    = {abs/1810.04805},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.04805},
  archivePrefix = {arXiv},
  eprint    = {1810.04805},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{ewicjwnbaixl,
author = {Popescu, Marius},
year = {2011},
month = {01},
pages = {634-639},
title = {Studying Translationese at the Character Level.},
journal = {International Conference Recent Advances in Natural Language Processing, RANLP}
}

@article{DBLPewfiovncoi,
  author       = {Karthikeyan K and
                  Zihan Wang and
                  Stephen Mayhew and
                  Dan Roth},
  title        = {Cross-Lingual Ability of Multilingual {BERT:} An Empirical Study},
  journal      = {CoRR},
  volume       = {abs/1912.07840},
  year         = {2019},
  url          = {http://arxiv.org/abs/1912.07840},
  eprinttype    = {arXiv},
  eprint       = {1912.07840},
  timestamp    = {Sun, 04 Dec 2022 18:42:29 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1912-07840.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{towardsdatascience,
  title = "{BERT Explained: State-of-the-Art Language Model for NLP}",
  author = "{Towards Data Science
Rani Horev}",
  howpublished = "{https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270}",
  note = "{Accessed on 10/05/2023}"
}

@misc{hug,
  title = "{Hugging Face}",
  author = "{Hugging Face}",
  howpublished = "{https://huggingface.co/bert-base-uncased}",
  note = "{Accessed on 05/05/2023}"
}




